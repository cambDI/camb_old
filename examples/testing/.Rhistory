predict(sl[[i]]$ci.spline, indexes)$y
}
sigma.matrix <- do.call(cbind, mclapply(1:ncol(m), FUN=list), GetCIsFromSplines, m, sl, mc.cores=1))
sigma.matrix <- do.call(cbind, mclapply(1:ncol(m), GetCIsFromSplines, m, sl, mc.cores=1))
dim(sigma.matrix)
sigmas <- apply(sweep(sigma.matrix,2,weights,`*`), 1, sum)
dim(sigma.matrix)
plot(sigmas, errors)
plot(errors, sigmas)
dim(sigmas)
dim(sigmas)
sigmas
CEC(sigmas, abs(errors))
GetWeights <- function(m, sl, cores = 1) {
sigmas <- do.call(cbind, mclapply(1:ncol(m), GetCIsFromSplines, m, sl, mc.cores=cores))
l <- GreedOptCEC(sigmas, errors, iter=50)
weights <- l$weights
plot(l$bests)
weights/sum(weights)
}
weights <- GetWeights(m, sl)
BuildEstimator <- function(x, folds, obs, preds) {
errors <- preds - obs
dms <- CreateDistanceMatrices(x, folds)
m <- CreateEstimatorMatrix(20, folds, dms, errors, obs, preds)
sl <- GetSigmaSplineList(m)
weights <- GetWeights(m, sl)
list(x = x, sl = sl, weights = weights, obs = obs, preds = preds, errors = errors)
}
# creates f distance matricies where f is the numer of folds
# each distance matrix is composed of the Euclidean distance of each instance in a fold to all the instances in the other folds
CreateDistanceMatrices <- function(x.train, folds) {
dms <- list()
for(fold in 1:length(folds)) {
out <- as.matrix(x.train[folds[[fold]], ])
ref <- as.matrix(x.train[-folds[[fold]], ])
dm <- matrix(NA, nrow=nrow(ref), ncol=nrow(out))
for(i in 1:nrow(out)) {
y <- as.vector(out[i,], mode="numeric")
y[is.na(y)] <- 0
dm[,i] <- colSums((t(ref)-y)^2)
}
dms[[fold]] <- dm
}
dms
}
# calculate the confine error-variance score for the instance in the col column of dm
confine <- function(col, dm, errors, obs, preds, N) {
x <- dm[,col]
sum((errors[order(x)[1:N]])^2)/N
}
confuse <- function(col, dm, errors, obs, preds, N) {
if(N==1) return(0)
x <- dm[,col]
var(errors[order(x)[1:N]])
}
convive <- function(col, dm, errors, obs, preds, N) {
if(N==1) return(0)
x <- dm[,col]
var(obs[order(x)[1:N]])
}
distance <- function(col, dm, errors, obs, preds, N) {
x <- dm[,col]
mean(sqrt(x[order(x)][1:N]))
}
diffNN <- function(col, dm, errors, obs, preds, N) {
x <- dm[,col]
abs(mean(obs[order(x)[1:N]]) - preds[col])
}
DoFold <- function(fold, dms, errors, obs, preds, N, func) {
sapply(1:ncol(dms[[fold]]), func, dms[[fold]], abs(errors)[-folds[[fold]]], obs[-folds[[fold]]], preds[folds[[fold]]], N)
}
CalculateErrorEstimates <- function(folds, dms, errors, obs, preds, N, func) {
num.folds <- length(folds)
estimates <- sapply(1:num.folds, DoFold, dms, errors, obs, preds, N, func)
estimates.vec <- do.call(c, estimates)
fold.vec <- do.call(c, folds)
match <- match(1:length(fold.vec), fold.vec)
estimates.vec[match]
}
CombineErrorEstimates <- function(N, folds, dms, errors, obs, preds) {
m <- CalculateErrorEstimates(folds, dms, errors, obs, preds, N, confine)
m <- cbind(m, CalculateErrorEstimates(folds, dms, errors, obs, preds, N, confuse))
m <- cbind(m, CalculateErrorEstimates(folds, dms, errors, obs, preds, N, convive))
m <- cbind(m, CalculateErrorEstimates(folds, dms, errors, obs, preds, N, distance))
m <- cbind(m, CalculateErrorEstimates(folds, dms, errors, obs, preds, N, diffNN))
m
}
CreateEstimatorMatrix <- function(Nmax, folds, dms, errors, obs, preds) {
m <- do.call(cbind, lapply(1:Nmax, CombineErrorEstimates, folds, dms, errors, obs, preds))
# remove the columns where all the results are 0 (this is columns 2 and 3 for the moment)
# m <- m[,-which(apply(m, 2, sum)==0)]
m <- m[,-c(2,3)]
}
# shortcut for finding maximum likelihood assuming 0 mean
FitSigma <- function(x) {
sum(x^2)/length(x)
}
ConvertToSigmaSplines <- function(x, spar = 0.8) {
splines <- list()
order <- order(x, decreasing=TRUE)
error.sort <- errors[order]
abs.error.sort <- abs(error.sort)
x.sort <- x[order]
hwidth <- floor(length(x)/10)
cis <- rep(NA, length(x))
inside <- hwidth:(length(x)-hwidth)
for(i in inside) {
set <- abs.error.sort[(i-hwidth):(i+hwidth)]
cis[i] <- FitSigma(abs.error.sort[(i-hwidth):(i+hwidth)])
}
splines$index.spline <- smooth.spline(x.sort, 1:length(x), spar = spar)
splines$ci.spline <- smooth.spline(inside, cis[inside], spar = spar)
return(splines)
}
GetSigmaSplineList <- function(m) {
sl <- list()
for(i in 1:ncol(m)) {
sl[[i]] <- ConvertToSigmaSplines(m[,i])
}
sl
}
GetSigmasFromSplines <- function(i, m, sl) {
indexes <- predict(sl[[i]]$index.spline, m[,i])$y
predict(sl[[i]]$ci.spline, indexes)$y
}
CEC <- function(x, y) {
if(sum(x)==0) return(0)
cor(x,y)/cor(sort(x), sort(y))
}
GreedOptCEC <- function(X, Y, iter = 100L){
bests       <- c()
N           <- ncol(X)
weights     <- rep(0L, N)
pred        <- 0 * X
sum.weights <- 0
while(sum.weights < iter) {
sum.weights   <- sum.weights + 1L
pred          <- (pred + X) * (1L / sum.weights)
CECs          <- apply(pred, 2, CEC, abs(Y))
best          <- which.max(CECs)
bests         <- c(bests, max(CECs))
weights[best] <- weights[best] + 1L
pred          <- pred[, best] * sum.weights
}
l <- list()
l$weights <- weights
l$bests <- bests
return(l)
}
GetWeights <- function(m, sl, cores = 1) {
sigmas <- do.call(cbind, mclapply(1:ncol(m), GetSigmasFromSplines, m, sl, mc.cores=cores))
l <- GreedOptCEC(sigmas, errors, iter=50)
weights <- l$weights
plot(l$bests)
weights/sum(weights)
}
BuildEstimator <- function(x, folds, obs, preds) {
errors <- preds - obs
dms <- CreateDistanceMatrices(x, folds)
m <- CreateEstimatorMatrix(20, folds, dms, errors, obs, preds)
sl <- GetSigmaSplineList(m)
weights <- GetWeights(m, sl)
list(x = x, sl = sl, weights = weights, obs = obs, preds = preds, errors = errors)
}
rf <- readRDS(file="../../../PPB/rf.rds")
bestTune <- which(rf$pred$.mtry == as.numeric(rf$bestTune))
length(bestTune)
CVpredictions <- rf$pred[bestTune, ]
order <- order(CVpredictions$rowIndex, decreasing=FALSE)
CVpredictions <- CVpredictions[order,]
obs <- CVpredictions$obs
preds <- CVpredictions$pred
folds <- list()
folds[[1]] <- which(CVpredictions$Resample == "Fold1.Rep1")
folds[[2]] <- which(CVpredictions$Resample == "Fold2.Rep1")
folds[[3]] <- which(CVpredictions$Resample == "Fold3.Rep1")
folds[[4]] <- which(CVpredictions$Resample == "Fold4.Rep1")
folds[[5]] <- which(CVpredictions$Resample == "Fold5.Rep1")
ss <- readRDS("../../../PPB/ss.rda")
x <- ss$x.train
estimator <- BuildEstimator(x, folds, obs, preds)
errors <- preds - obs
GetWeights <- function(m, errors, sl, cores = 1) {
sigmas <- do.call(cbind, mclapply(1:ncol(m), GetSigmasFromSplines, m, sl, mc.cores=cores))
l <- GreedOptCEC(sigmas, errors, iter=50)
weights <- l$weights
plot(l$bests)
weights/sum(weights)
}
BuildEstimator <- function(x, folds, obs, preds) {
errors <- preds - obs
dms <- CreateDistanceMatrices(x, folds)
m <- CreateEstimatorMatrix(20, folds, dms, errors, obs, preds)
sl <- GetSigmaSplineList(m)
weights <- GetWeights(m, errors, sl)
list(x = x, sl = sl, weights = weights, obs = obs, preds = preds, errors = errors)
}
estimator <- BuildEstimator(x, folds, obs, preds)
CreateNewDistanceMatrix <- function(x, x.new) {
out <- x.new
ref <- x
dm <- matrix(NA, nrow=nrow(ref), ncol=nrow(out))
x <- as.matrix(ref)
for(i in 1:nrow(out)) {
y <- as.vector(out[i,], mode="numeric")
y[is.na(y)] <- 0
dm[,i] <- colSums((t(x)-y)^2)
}
max <- max(dm)
for(i in 1:nrow(dm)) {
dm[i,i] <- max
}
dm
}
DoNew <- function(dm, errors, obs, preds, N, func) {
sapply(1:ncol(dm), func, dm, abs(errors), obs, preds, N)
}
CombineNewErrorEstimates <- function(N, dm, errors, obs, preds) {
m <- DoNew(dm, errors, obs, preds, N, confine)
m <- cbind(m, DoNew(dm, errors, obs, preds, N, confuse))
m <- cbind(m, DoNew(dm, errors, obs, preds, N, convive))
m <- cbind(m, DoNew(dm, errors, obs, preds, N, distance))
m <- cbind(m, DoNew(dm, errors, obs, preds, N, diffNN))
m
}
CreateNewEstimatorMatrix <- function(Nmax, dm, errors, obs, preds) {
m <- do.call(cbind, lapply(1:Nmax, CombineNewErrorEstimates, dm, errors, obs, preds))
m[,-c(2,3)]
}
GetNewSigmas <- function(nm, sl, weights, cores=1) {
sigma.matrix <- do.call(cbind, mclapply(1:ncol(nm), GetSigmasFromSplines, nm, sl, mc.cores=cores))
apply(sweep(sigma.matrix,2,weights,`*`), 1, sum)
}
PredictSigmas <- function(x.new, sl, weights) {
dm <- CreateNewDistanceMatrix(x, x.new)
Nmax <- 20
nm <- CreateNewEstimatorMatrix(Nmax, dm, errors, obs, preds)
GetNewSigmas(nm, sl, weights)
}
dm <- CreateNewDistanceMatrix(x, x)
sigmas <- PredictSigmas(x, estimator$sl, estimator$weights)
plot(abs(errors), sigmas)
CEC(sigmas, abs(errors))
errors <- preds - obs
dms <- CreateDistanceMatrices(x, folds)
m <- CreateEstimatorMatrix(20, folds, dms, errors, obs, preds)
sl <- GetSigmaSplineList(m)
weights <- GetWeights(m, errors, sl)
sigmas <- do.call(cbind, mclapply(1:ncol(m), GetSigmasFromSplines, m, sl, mc.cores=1))
CEC(sigmas, abs(errors))
abs(errors)
GetWeights <- function(m, errors, sl, cores = 1) {
sigma.matrix <- do.call(cbind, mclapply(1:ncol(m), GetSigmasFromSplines, m, sl, mc.cores=cores))
l <- GreedOptCEC(sigma.matrix, errors, iter=50)
weights <- l$weights
plot(l$bests)
weights/sum(weights)
}
sigma.matrix <- do.call(cbind, mclapply(1:ncol(m), GetSigmasFromSplines, m, sl, mc.cores=1))
sigmas <- apply(sweep(sigma.matrix,2,weights,`*`), 1, sum)
CEC(sigmas, abs(errors))
plot(sigmas, abs(errors)
)
CEC(sigmas, abs(errors))
sigmas <- PredictSigmas(x, estimator$sl, estimator$weights)
BuildEstimator <- function(x, folds, obs, preds, Nmax) {
errors <- preds - obs
dms <- CreateDistanceMatrices(x, folds)
m <- CreateEstimatorMatrix(Nmax, folds, dms, errors, obs, preds)
sl <- GetSigmaSplineList(m)
weights <- GetWeights(m, errors, sl)
list(x = x, sl = sl, weights = weights, obs = obs, preds = preds, errors = errors, Nmax = Nmax)
}
estimator$Nmax <- 20
PredictSigmas <- function(x, estimator) {
dm <- CreateNewDistanceMatrix(estimator$x, x)
nm <- CreateNewEstimatorMatrix(estimator$Nmax, dm, estimator$errors, estimator$obs, estimator$preds)
GetNewSigmas(nm, estimator$sl, weights)
}
sigmas <- PredictSigmas(x, estimator)
CEC(sigmas, abs(errors))
plot(sigmas, abs(errors))
# estimates on new predictions
CreateNewDistanceMatrix <- function(x, x.new) {
out <- x.new
ref <- x
dm <- matrix(NA, nrow=nrow(ref), ncol=nrow(out))
x <- as.matrix(ref)
for(i in 1:nrow(out)) {
y <- as.vector(out[i,], mode="numeric")
y[is.na(y)] <- 0
dm[,i] <- colSums((t(x)-y)^2)
}
#max <- max(dm)
#for(i in 1:nrow(dm)) {
#  dm[i,i] <- max
#}
dm
}
CreateNewDistanceMatrix <- function(x, x.new) {
out <- x.new
ref <- as.matrix(x)
dm <- matrix(NA, nrow=nrow(ref), ncol=nrow(out))
for(i in 1:nrow(out)) {
y <- as.vector(out[i,], mode="numeric")
y[is.na(y)] <- 0
dm[,i] <- colSums((t(ref)-y)^2)
}
#max <- max(dm)
#for(i in 1:nrow(dm)) {
#  dm[i,i] <- max
#}
dm
}
PredictSigmas <- function(x, estimator) {
dm <- CreateNewDistanceMatrix(estimator$x, x)
nm <- CreateNewEstimatorMatrix(estimator$Nmax, dm, estimator$errors, estimator$obs, estimator$preds)
GetNewSigmas(nm, estimator$sl, weights)
}
sigmas <- PredictSigmas(x, estimator)
CEC(sigmas, abs(errors))
plot(sigmas, abs(errors))
# estimates on new predictions
CreateNewDistanceMatrix <- function(x, x.new) {
out <- x.new
ref <- as.matrix(x)
dm <- matrix(NA, nrow=nrow(ref), ncol=nrow(out))
for(i in 1:nrow(out)) {
y <- as.vector(out[i,], mode="numeric")
y[is.na(y)] <- 0
dm[,i] <- colSums((t(ref)-y)^2)
}
#max <- max(dm)
#for(i in 1:nrow(dm)) {
#  dm[i,i] <- max
#}
dm
}
dm <- CreateNewDistanceMatrix(estimator$x, x)
dim(dm)
nm <- CreateNewEstimatorMatrix(estimator$Nmax, dm, estimator$errors, estimator$obs, estimator$preds)
dim(nm)
sigmas <- PredictSigmas(ss$y.train, estimator)
dim(ss$y.train)
sigmas <- PredictSigmas(ss$x.test, estimator)
dim(ss$x.test)
ss$x.test
SplitSet
library(camb)
SplitSet
sigmas <- PredictSigmas(ss$x.holdout, estimator)
holdout.predictions <- as.vector(predict(rf, newdata = ss$x.holdout))
holdout.predictions
holdout.errors <- holdout.predictions - ss$y.holdout
holdout.errors
CEC(sigmas, abs(holdout.errors))
sigmas <- PredictSigmas(ss$x.holdout, estimator)
sigmas
plot(abs(holdout.errors), sigmas)
plot(holdout.errors, sigmas)
CEC(sigmas, abs(holdout.errors))
load("../../../logP/5_ensembles/gbm/gbm.rda")
gbm$bestTune
head(gbm$pred)
gbm$bestTune
head(gbm$pred[,c(5,4,6)])
which(gbm$pred[,c(5,4,6)] == gbm$bestTune)
gbm$bestTune
which(gbm$pred[,c(5,4,6)] == as.numeric(gbm$bestTune))
length(which(gbm$pred[,c(5,4,6)] == as.numeric(gbm$bestTune)))
head(gbm$pred[,c(5,4,6)])
length(which(as.matrix(gbm$pred[,c(5,4,6)]) == as.numeric(gbm$bestTune)))
gbm$bestTune
gbm$pred[,c(5,4,6)]) == gbm$bestTune
gbm$pred[,c(5,4,6)])
gbm$pred[,c(5,4,6)] == gbm$bestTune
setwd("~/Dropbox/COX def")
estimator <- readRDS("estimator.rds")
prediction <- PredictSigmas(x.test, estimator)
library(errorestimatoR)
load("GP_pndot.RData")
prediction <- PredictSigmas(x.test, estimator)
errors <- z.test - y.test
sigmas <- prediction$sigmas
CEC(abs(errors), z.test_var)
CEC(abs(errors), sigmas)
cor(abs(errors), z.test_var, method="spearman")
cor(abs(errors), sigmas, method="spearman")
b <- readRDS("error.rds")
sigmas <- b$prediction$sigmas
CEC(abs(errors), z.test_var)
CEC(abs(errors), sigmas)
plot(errors, z.test_var, ylim=c(0, 1.4))
points(errors, sigmas, col=2)
CEC(abs(errors), z.test_var)
CEC(abs(errors), sigmas)
(length(which(abs(errors) < sigmas))/length(errors)) * 100
(length(which(abs(errors) < z.test_var))/length(errors)) * 100
(length(which(abs(errors) < sqrt(sigmas)))/length(errors)) * 100
(length(which(abs(errors) < sqrt(z.test_var)))/length(errors)) * 100
(length(which(abs(errors) < sqrt(z.test_var)))/length(errors)) * 100
(length(which(abs(errors) < sqrt(sigmas)))/length(errors)) * 100
setwd("~/Dropbox/projects/camb/examples/testing")
library(camb)
library(camb)
detach("package:camb", unload=TRUE)
library("camb", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(camb)
detach("package:camb", unload=TRUE)
library("camb", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
setwd("~/Dropbox/projects/camb/examples/testing")
StandardiseMolecules(structures.file="structures.sdf",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
remove.inorganic=TRUE,
fluorine.limit=3,
chlorine.limit=3,
bromine.limit=3,
iodine.limit=3,
min.mass.limit=20,
max.mass.limit=900)
StandardiseMolecules(structures.file="structures.sdf",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
remove.inorganic=TRUE,
fluorine.limit=3,
chlorine.limit=3,
bromine.limit=3,
iodine.limit=3,
min.mass.limit=20,
max.mass.limit=900)
StandardiseMolecules <- function(structures.file,
standardised.file,
removed.file,
remove.inorganic = FALSE,
fluorine.limit = -1,
chlorine.limit = -1,
bromine.limit = -1,
iodine.limit = -1,
min.mass.limit = -1,
max.mass.limit = -1,
number.processed = -1) {
# handle non-existant file
if (!file.exists(structures.file)) {
print("File does not exist")
}
# deal with sdf or smi difference
split <- strsplit(structures.file, "\\.")[[1]]
filetype <- split[length(split)]
if(tolower(filetype) == "sdf") {
print("Standardising Structures: Reading SDF (R)")
sink(file="standardisation.log", append=FALSE, split=FALSE)
.C("R_standardiseMolecules",
structures.file,
standardised.file,
removed.file,
as.integer(1), # process SDF
as.integer(remove.inorganic),
as.integer(fluorine.limit),
as.integer(chlorine.limit),
as.integer(bromine.limit),
as.integer(iodine.limit),
as.integer(min.mass.limit),
as.integer(max.mass.limit),
as.integer(number.processed))
sink()
}
else if(tolower(filetype) == "smi") {
print("Standardising Structures: Reading SMILES (R)")
sink(file="standardisation.log", append=FALSE, split=FALSE)
.C("R_standardiseMolecules",
structures.file,
standardised.file,
removed.file,
as.integer(0), # process SMILES
as.integer(remove.inorganic),
as.integer(fluorine.limit),
as.integer(chlorine.limit),
as.integer(bromine.limit),
as.integer(iodine.limit),
as.integer(min.mass.limit),
as.integer(max.mass.limit),
as.integer(number.processed))
sink()
}
else {
print("Unrecognised file type")
}
}
StandardiseMolecules(structures.file="structures.sdf",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
remove.inorganic=TRUE,
fluorine.limit=3,
chlorine.limit=3,
bromine.limit=3,
iodine.limit=3,
min.mass.limit=20,
max.mass.limit=900)
detach("package:camb", unload=TRUE)
library("camb", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
StandardiseMolecules(structures.file="structures.sdf",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
remove.inorganic=TRUE,
fluorine.limit=3,
chlorine.limit=3,
bromine.limit=3,
iodine.limit=3,
min.mass.limit=20,
max.mass.limit=900)
