\documentclass[twoside,a4wide,12pt]{article}
%\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em,frame=single}
%\DefineVerbatimEnvironment{Soutput}{Verbatim} {xleftmargin=2em,frame=single}
\usepackage[left=2.5cm,top=2cm,right=2cm,bottom=2.5cm,bindingoffset=0.5cm]{geometry}
\usepackage{amsmath} 
\usepackage[affil-it]{authblk}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{pdflscape}
\usepackage[backend=bibtex,sorting=none,style=ieee]{biblatex}
\usepackage{setspace}
\bibliography{biblio}


\title{Proteochemometrics (PCM) with 'camb'\\
{\bf C}hemistry {\bf A}ware {\bf M}odel {\bf B}uilder\\
}

\author[1,3]{\rm Isidro Cortes-Ciriano\thanks{isidrolauscher@gmail.com}} 
\author[2,3]{\rm Daniel Murrell\thanks{dsmurrell@gmail.com}}
\affil[1]{Unite de Bioinformatique Structurale, Institut Pasteur and CNRS UMR 3825, Structural Biology and Chemistry Department, 25-28, rue Dr. Roux, 75 724 Paris, France.}
\affil[2]{Unilever Centre for Molecular Science Informatics, Department of Chemistry, University of Cambridge, Cambridge, United Kingdom.}
\affil[3]{Equal contributors}
\setlength{\parindent}{0pt}


\begin{document}

\maketitle
\onehalfspacing

<<include=FALSE>>=
opts_chunk$set(concordance=TRUE)
opts_chunk$set(dev='pdf')
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

<<echo=FALSE,results='hide'>>=
options(width=60)
suppressWarnings(library(png,quietly=TRUE,warn.conflicts=FALSE))
suppressWarnings(library(caret,quietly=TRUE,warn.conflicts=FALSE))
suppressWarnings(library(doMC,quietly=TRUE,warn.conflicts=FALSE))
library(ggplot2,quietly=TRUE)
@
\maketitle

In the following sections, we present a pipeline to generate a whole Proteochemometric (PCM) pipeline. For futher details about PCM, the interested reader is referred to ref
\cite{review_pcm} and \cite{cortesReview}.
Firstly, we load the package and set the working directory:
<<echo=FALSE,results='hide',warning=FALSE,message=FALSE>>=
library(camb)
setwd('/Users/icortes/Desktop/camb_final/camb/examples/PCM/COX')
@
<<echo=TRUE,results='hide',warning=FALSE,message=FALSE>>=
library(camb)
#setwd('path_to_working_directory/camb/examples/COX')
@

\section{Compounds}

\subsection{Reading and Preprocessing}
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
smiles <- read.table("smiles_COX.smi", header=FALSE,comment.char=c(""))
@
Given that some smiles contain smarts patterns where the hash symbol is present, we need to avoid switch of the argument comment.char in order not to clip the smiles:

<<echo=TRUE,results='hide',warning=FALSE,message=FALSE,eval=FALSE>>=
StandardiseMolecules(structures.file="smiles_COX.smi",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
output="standardisation_COX_info.csv",
remove.inorganic=TRUE,
fluorine.limit=-1,
chlorine.limit=-1,
bromine.limit=-1,
iodine.limit=-1,
min.mass.limit=-1, #suggested value 20
max.mass.limit=-1) #suggested value  900)
@
The properties of all molecules and the index (in the column 'kept') indicating which molecules were deleted are written to a file called standardisation\_COX\_info.csv.

<<echo=TRUE,results='hide',warning=FALSE,message=FALSE,eval=FALSE>>=
standardised_info <- read.table("standardisation_COX_info.csv",header=TRUE,sep="\t")
head(standardised_info)
@

In this case, the criteria we chose to remove compounds (the arguments of the StandardiseMolecules function) were not really stringent, so all molecules were kept.
This can be seen in the kept field, given that for all compounds (rows) we have a value equal to -1.\\
Similarly, the properties of a .sdf file can be accessed witn the function:
<<echo=TRUE,results='hide',warning=FALSE,message=FALSE,eval=FALSE>>=
ShowPropertiesSDF("standardised.sdf",type=1)
@
A given property can be accessed, or all of them. In the latter case, a data.frame with all properties is returned:
<<echo=TRUE,results='hide',warning=FALSE,message=FALSE,eval=FALSE>>=
GetPropertySDF("standardised.sdf",property="property_name",number_processed=10,type=1)
all_properties <- GetPropertiesSDF("standardised.sdf",number_processed=10,type=1)
head(all_properties)
@

\subsection{PaDEL Descriptors}
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
descriptors_COX <- GeneratePadelDescriptors( +
  standardised.file="smiles_COX.smi",threads = 1)
descriptors <- RemoveStandardisedPrefix(descriptors)
saveRDS(descriptors, file="Padel_COX.rds")
descriptors <- readRDS("Padel_COX.rds")
@

Sometimes, some descriptors are not calculated for all molecules, thus giving a 'NA' or 'Inf' as descriptor values.
Instead of removing that descriptor for all molecules, the missing descriptor values can be imputed from the corresponding descriptor values of the rest of molecules.
Descriptor values equalt to 'Inf' are converted to 'NA'.
The R package {\it impute} is required. Depending on the R version, it can be accessed from either CRAN or Bioconductor.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),eval=FALSE>>=
descriptors <- ReplaceInfinitesWithNA(descriptors)
descriptors <- ImputeFeatures(descriptors)
@

\subsection{Circular Morgan Fingerprints}
The python library RDkit is required since the function 'MorganFPs' uses a python script for the calculation.
When using integrated development environments (IDE) such as RStudio,
the environment variables might not be seen.
We can redefine them with the R function 'Sys.setenv'.
In any case, the function 'MorganFPs' requires this information in the arguments 'PythonPath' and 'RDkitPath'.
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),eval=FALSE>>=
Sys.setenv(RDBASE="/usr/local/share/RDKit")
Sys.setenv(PYTHONPATH="/usr/local/lib/python2.7/site-packages")
fps_COX_512 <- MorganFPs(bits=512,radius=2,type='smi',mols='smiles_COX.smi', 
                         output='COX',keep='hashed_counts',
                         RDkitPath='/usr/local/share/RDKit', 
                         PythonPath='/usr/local/lib/python2.7/site-packages',
                         verbose=TRUE)
saveRDS(fps_COX_512,file="fps_COX_512.rds")
fps_COX_512 <- readRDS("fps_COX_512.rds")
@

\section{Targets}

\subsection{Read and Preprocessing}
We read the amino acids from a .csv file:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),eval=FALSE,tidy=TRUE>>=
amino_compound_IDs <- read.table("AAs_COX.csv",sep=",",
                                 header=TRUE,colClasses=c("character"),
                                 row.names=1)
amino_compound_IDs <- amino_compound_IDs[,2:ncol(amino_compound_IDs)]
@
Now, 5 Z-scales are calculated, which will serve to describe the target space in the machine learning models.
Subsequently, we save the descriptors to a .rds file.
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),eval=FALSE,tidy=TRUE>>=
amino_compound_IDs_zscales <- AA_descs(Data=amino_compound_IDs,type="Z5")
saveRDS(amino_compound_IDs_zscales,file="Z5_COX.rds")
@

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE>>=
amino_compound_IDs_zscales <-readRDS("Z5_COX.rds")
@

In the case that we needed whole sequence descriptors, they can be calculated with the function 'SeqDescs'. 
The function takes as argument either a UniProt identifier, or either a matrix or dataframe with the protein sequences.
If a UniProt identifier is provided, the function gets firstly the sequence and then calculates the descriptors on the sequence.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
Seq_descriptors_P00374 <- SeqDescs("P00374",UniProtID=TRUE,type=c("AAC","DC"))
@
The available types of whole sequence descriptors are:\cite{protr}
\begin{itemize}
\item Amino Acid Composition ("AAC")\\
\item Dipeptide Composition ("DC")\\
\item Tripeptide Composition ("TC")\\
\item Normalized Moreau-Broto Autocorrelation ("MoreauBroto")\\
\item Moran Autocorrelation ("Moran")\\
\item Geary Autocorrelation ("Geary")\\
\item  CTD (Composition/Transition/Distribution) ("CTD")\\
\item Conjoint Traid ("CTriad")\\
\item Sequence Order Coupling Number ("SOCN")\\
\item Quasi-sequence Order Descriptors ("QSO")\\
\item Pseudo Amino Acid Composition ("PACC")\\
\item Amphiphilic Pseudo Amino Acid Composition ("APAAC")\\
\end{itemize}

\subsection{Reading the Data-set Information}
Now, we are going to read the file with the information about the dataset, namely: target names, bioctivities, etc..
Note that when reading smiles from a .csv file into an R dataframe, the smiles are clipped after a hash ('\#') symbol.
A good practice is thus to also keep the smiles alone in a \{.smi,.smiles\} file.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE>>=
dataset <- readRDS("COX_dataset_info.rds")
bioactivity <- dataset$standard_value
@
The bioactivity is in nM. We convert it to pIC50:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE>>=
bioactivity <- bioactivity * 10^-9
bioactivity <- -log(bioactivity,base=10)
@

\section{Data-set Visualization}
Compounds can be depicted with the function 'PlotMolecules'. It returns a list of four plots, and plots can also be written into a .pdf file.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE,results='hide',echo=FALSE>>=
# we redefine the function isnot
is.intalled <- function(mypkg) is.element(mypkg, installed.packages()[,1])
@

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,fig.align='center',fig.cap="Example of compoud depiction.",out.width='12cm',eval=TRUE,echo=TRUE,message=FALSE>>=
plot_molecules <- PlotMolecules("standardised.sdf",IDs=c(1,2,3,4),pdf.file=NULL,useNameAsTitle=TRUE,PDFMain=NULL) 
print(plot_molecules[[1]])
@

We can have a look at the response variable:
<<highlight=TRUE,results='hide',tidy.opts=list(width.cutoff=50),tidy=TRUE,fig.align='center',fig.cap="Bioactivity Distribution",out.width='12cm',eval=TRUE>>=
dens_resp <- DensityResponse(bioactivity,xlab="pIC50",main="",ylab="Densitiy",TitleSize=30,XAxisSize=22,YAxisSize=22,TitleAxesSize=24,AngleLab=0,lmar=0,rmar=0,bmar=0,tmar=0,binwidth=0.3)
@

Plotting a PCA analysis of the target descriptors gives:
<<highlight=TRUE,results='hide',tidy.opts=list(width.cutoff=50),tidy=TRUE,fig.align='center',fig.cap="PCA Analysis on the\nAmino Acid Descriptors",eval=TRUE>>=
target_PCA <- PCAProt(amino_compound_IDs_zscales,
                      SeqsName=dataset$accession)
plot_PCA_Cox <- PCAProtPlot(target_PCA,PointSize=10,main="",TitleSize=30,XAxisSize=20,YAxisSize=20,TitleAxesSize=28,LegendPosition="bottom",RowLegend=3,ColLegend=5,LegendTitleSize=15,LegendTextSize=15)
@

Similarly, we can analyze the chemical space by calculating pairwise compound similarities based upon the compound descriptors. In this case, we use the Jaccard metric to calculate the distance between compounds.
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
pw_dist_comp_fps <- PairwiseDist(fps_COX_512,method="jaccard")
saveRDS(pw_dist_comp_fps,file="pairwise_dist_COX.rds")
@

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE>>=
pw_dist_comp_fps <- readRDS("pairwise_dist_COX.rds")
plot_pwd <- PairwiseDistPlot(pw_dist_comp_fps,xlab="Jaccard Similarity",ylab="Density",TitleSize=26,XAxisSize=20,YAxisSize=20,TitleAxesSize=24,lmar=0,rmar=0,bmar=0,tmar=0,AngleLab=0)
@

<<highlight=TRUE,tidy=TRUE,fig.align='center',fig.cap="Density of the response variable (upper panel). Pairwise Compound Jaccard Similarity (bottom pannel)",fig.width='10cm',fig.height='25cm'>>=
grid.arrange(dens_resp,plot_pwd,nrow=2)
@

%\newpage
Before any modeling attempt, it is interesting to know which is the maximum performance achievable {\it on the basis} of the available data.\\ 
By that, we consider the experimental uncertainty and the size of our data-set. 
In this case, a Gaussian Process (GP) model was trained in Matlab (data not shown) where the experimental uncertainty was optimized as a hyperparameter. The obtained value was 0.60.\\
This value is in accordance with recently prublished value of 0.68 for public IC50 data.
With the function 'MaxPerf', we can calculate the manximum achievable performance:

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
max_performance <- MaxPerf(meanNoise=0,sdNoise=0.6,meanResp=mean(bioactivity),sdResp=sd(bioactivity),lenPred=800)
@

The function returns a list of four plots. By using the function 'plotGrid' we can create a grid of plots in the following way:

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
plotGrid(plots=c(max_performance$p1,max_performance$p2,max_performance$p3,max_performance$p4))
@

\section{Statistical Pre-processing}
Bioactivity annotations in ChEMBL are sometimes redundant, meaning that for a given target-compound combination there are more than one annotated values.\\
To avoid this issue, we will remove redundant pairs and will keep the mean bioactivity value for those compound-target combinations repeated.\\
%To do that, we run the file \"remove_duplicates.R\":
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
source("remove_duplicates.R")
@

Now, we load the dataset without repetitions generated in the previous step. In addition, we remove those columns not containing descriptors (e.g. compound name):
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
dataset <- readRDS("Whole_dataset_NO_REP.rds")
killset <- expression(c(tid,pref_name,accession,organism,chembl_id,standard_value,standard_units, standard_type,chembl_id.1,Name,Name.1,Name.2,rows))
bioactivity <- dataset$standard_value
compound_IDs <- dataset$chembl_id.1
dataset <- subset(dataset,select=-eval(killset))
@

Subsequently, we split the dataset into a training (70\%) and a hold-out (external; 30\%) set that will be used to assess the predictive ability of the models. Furthermore, we remove the following descriptors: (i) those with a variance close to zero (near-zero variance), and (ii) those highly correlated:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
# split the dataset into a training and holdout set
dataset <- SplitSet(compound_IDs, dataset, bioactivity, percentage=30)

# remove the descriptors that are highly correlated or have low variance
dataset <- RemoveNearZeroVarianceFeatures(dataset,frequencyCutoff=30/1)
dataset <- RemoveHighlyCorrelatedFeatures(dataset)
@

We convert the descriptors to z-scores by centering them to zero mean and scaling their values to unit variance:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
dataset <- PreProcess(dataset)
@

Given that cross-validation (CV) will be used to optimize the hyperparameters of the models, we divide the training setin 5 folds:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
dataset <- GetCVTrainControl(dataset,seed=1)
saveRDS(dataset, file="dataset_COX_preprocessed.rda")
@
All models are trained with the same CV options to allow ensemble modeling (see below).
These options are:
method='cv', number=folds, repeats=repeats, returnResamp='none',
returnData=FALSE, savePredictions=TRUE,
verboseIter=TRUE, allowParallel=TRUE and
index=createMultiFolds(y.train, k=folds, times=repeats)).

\section{Model Training}

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE>>=
dataset <- readRDS("dataset_COX_preprocessed.rda")
# Number of cores to be used during model training
cores <- 3
registerDoMC(cores) 
@

\subsection{Support Vector Machines (SVM)}
Firstly, a SVM will be trained\cite{svmreview}. We define an exponential grid (base 2) to optimize the hyperparameters:

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
method <- "svmRadial"
exp_grid <- expGrid(power.from=-8,power.to=-6,power.by=2,base=2)
tune.grid <- expand.grid(.sigma = exp_grid)
@

Training:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
modelCoxSVMrad <- train(dataset$x.train, dataset$y.train, method, tuneGrid=tune.grid, trControl=dataset$trControl)
saveRDS(modelCoxSVMrad, file="model_SVM.rds")
@

\subsection{Random Forest}
We proceed similarly in the case of a random forest (RF) model\cite{rf}.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
method <- "rf"

modelCoxRF<- train(dataset$x.train, dataset$y.train, method, trControl=dataset$trControl)
saveRDS(modelCoxRF, file="model_RF.rds")
@
Loading the RF model.
<<highlight=FALSE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE>>=
modelCoxRF<- readRDS("model_RF.rds")
@

\subsection{Gradient Boosting Machine}
We proceed similarly in the case of a gradient boosting machine (GBM) model\cite{gbm}.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
method <- "gbm"
tune.grid <- expand.grid(.shrinkage=c(0.04, 0.08, 0.12, 0.16), 
                         .n.trees=c(500), .interaction.depth=c(25))   
modelCoxGBM<- train(dataset$x.train, dataset$y.train, method, tuneGrid=tune.grid, trControl=dataset$trControl)
saveRDS(modelCoxGBM, file="model_GBM.rds")
@


\section{Model Evaluation}

Once the models are trained, the cross validated metrics can be calculated:
We assume the metric used for the choice of the best combination of hyperparameters is 'RMSE'.
In the following we focus on the RF model, though the same can be applied to the GBM and SVM models.

<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE>>=
RMSE_CV_rf = signif(min(as.vector(na.omit(modelCoxRF$results$RMSE))), 
                    digits=3)
Rsquared_CV_rf = modelCoxRF$results$Rsquared[which(modelCoxRF$results$RMSE %in% min(modelCoxRF$results$RMSE, na.rm=TRUE))]
print(RMSE_CV_rf)
print(Rsquared_CV_rf)
@

On the basis of the soundness of the obtained models, we predict the values for the external (hold-out) set:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,warning=FALSE,message=FALSE,eval=FALSE>>=
holdout.predictions <- as.vector(predict(modelCoxRF$finalModel, newdata = dataset$x.holdout))
@

We evaluate the predictive ability of our models by calculation the following statistical metrics:\\

{\bf Internal validation:}
\\
\begin{equation}
q_{{\it int}}^{2} = 1 - \frac {\sum_{i=1}^{N} (y_{i} - \widetilde{y}_{i})^{2}} {\sum_{i=1}^{N} (y_{i} - \bar{y}_{tr})^{2}}
\end{equation}
% cross-validated correlation coefficient

\begin{equation}
RMSE_{int} = \frac {\sqrt {(y_i - \widetilde{y}_i)^{2}}} {N}
\end{equation}

where $N$, $y_i$, $\widetilde{y}_i$ and $\bar{y}_{tr}$ represent the size of the training set, the observed, the predicted and the averaged values of the response variable for those datapoints included in the training set. The {\it i}th position within the training set is defined by {\it i}.  
\\
\\
{\bf External validation:}
\\

\begin{equation}
q_{{\it ext}}^{2} = 1 - \frac {\sum_{j=1}^{N} (y_j-\widetilde{y}_j)^{2}}  {\sum_{j=1}^{N} (y_j - \bar{y}_{ext})^{2}}
\end{equation}

\begin{equation}
RMSE_{ext} = \frac {\sqrt {(y_i - \widetilde{y}_i)^{2}}} {N} 
\end{equation}

\begin{equation}
R_{ext}^{2} = \frac {{\sum_{i=1}^{N} (y_{i} - \bar{y}_{ext})}  (\widetilde{y}_{i} - \overset{-}{\widetilde{y}_{ext}})} 
{\sqrt{\sum_{i=1}^{N} (y_{i} - \bar{y}_{ext})^{2} \sum{ (\widetilde{y}_{i} - \overset{-}{\widetilde{y}_{ext}})^{2}}}}
\end{equation}

\begin{equation}
R_{0\:ext}^2 = 1 - \frac {\sum_{j=1}^{N} (y_{j} - \widetilde{y}_{j}^{ r0})^{2}} {\sum_{j=1}^{N} (y_{j} - \bar{y}_{ext})^{2}} 
\end{equation}

where $N$, $y_j$, $\widetilde{y}_j$, $\bar{y}_{ext}$ and $\breve{y}_j$ represent the size of the training set, the observed, the predicted, the averaged values and the fitted
values of the response variable for those datapoints comprising the external set. The {\it j}th position within the external set is defined by {\it j}. $R_{0\:ext}^2$ is the square of the coefficient of determination through the origin, being $\widetilde{y}_{j}^{ r0} = k \widetilde{y}_j$ the regression through the origin (observed versus predicted) and $k$ its slope.\\
For a detailed discussion of both the evaluation of the predictive ability through the external set and different formulations for $q^{2}$, see ref.\cite{consonni}. 
To be considered as predictive, a model must satisfy the following criteria:\cite{beware,earnest}
\\
\begin{enumerate}
\item $q_{{\it int}}^{2} > 0.5$
\item $R_{ext}^2 > 0.6$
\item $ \frac {(R_{ext}^2 - R_{0\:ext}^2)} {R_{ext}^2} < 0.1$
\item $0.85 \leq k \leq 1.15$
\end{enumerate}

The metrics for the external validation are given by:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
MetricsRf <- Validation(holdout.predictions,dataset$y.holdout)
@

To have a look at the correlation between predicted and observed values, we can use the 'CorrelationPlot' function:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE,results='hide',echo=FALSE>>=
# loading the z.test values...
holdout.predictions <- readRDS("/Users/icortes/Desktop/COX/ztest_doc.rds") 
dataset$y.holdout <- readRDS("/Users/icortes/Desktop/COX/ytest_doc.rds")
@


<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,fig.align='center',fig.cap="Observed vs Predicted">>=
CorrelationPlot(pred=holdout.predictions,obs=dataset$y.holdout,PointSize=3,ColMargin='blue',TitleSize=26,XAxisSize=20,YAxisSize=20,TitleAxesSize=24,margin=2,PointColor="black",PointShape=16,MarginWidth=1,AngleLab=0,xlab="Observed",ylab="Predicted")
@

\section{Ensemble Modeling}
In the following section, we applied two ensemble modeling techniques, namely greedy optimization and model stacking, to create ensembles of models.
Further information can be found in ref \cite{cortesCOX} and \cite{caretEnsemble}.
<<highlight=FALSE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=TRUE,echo=FALSE,message=FALSE,results='hide'>>=
suppressWarnings(require(devtools,quietly=T,warn.conflicts=FALSE)) || stop("package devtools need to be installed")
suppressWarnings(require(pbapply,quietly=TRUE,warn.conflicts=FALSE)) || stop("package pbapply need to be installed")
@

To get (i) the training, (ii) the external set, (iii)the transformation applied to center and scale the descriptors before model training, and (iv) the model training options, we run the following lines:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
data <- list()
attach(dataset)
data$transformation <- transformation
data$x.train <- x.train
data$y.train <- y.train
data$x.test <- x.holdout # external set
data$y.test <- y.holdout # external set
data$trControl <- trControl
saveRDS(data, file="data_ensemble.rds")
detach(dataset)
@
Subsequently, we load the models previously trained.
The list of models is in the file modelsEnsemble.
Once all models have been loaded, we create the following ensembled:
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
greedy <- caretEnsemble(all.models, iter=1000L)
sort(greedy$weights, decreasing=TRUE)
@

Subsequently, we load the models previously trained.
The list of models is in the file modelsEnsemble.
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
  all.models <- list()
models <- as.vector(read.table("modelsEnsemble")$V1)

for (i in 1:length(models)){
  model_load = paste("readRDS('",models[i],"')",sep="")
  assign(paste("model_",i,sep=""), eval(parse(text=model_load)))
  all.models[[length(all.models)+1]] <- eval(parse(text=paste("model_",i,sep="")))
}

names(all.models) <- sapply(all.models, function(x) x$method)
sort(sapply(all.models, function(x) min(as.vector(na.omit(x$results$RMSE)))))
@

Once all models have been loaded, we create the following ensembled:
  %\begin{enumerate}
%\item Greedy (now it can only optimize the hold-out RMSE)
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
  greedy <- caretEnsemble(all.models, iter=1000L)
sort(greedy$weights, decreasing=TRUE)
@

%\item Model Stacking
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
  # make a linear regression ensemble
  linear <- caretStack(all.models, method='glm')
summary(linear$ens_model$finalModel)

# make Elastic Net ensemble
enet_ens <- caretStack(all.models, method='enet')
coefs_enet_ens <- enet_ens$ens_model$finalModel$beta.pure +
[ncol(enet_ens$ens_model$finalModel$beta.pure)+1,]

# make SVM linear ensemble
trControl <- trainControl(method = "cv",  number=5)
tune.grid <- expand.grid(.C=expGrid(power.from=-14,
                                    power.to=10,power.by=1,base=2))
linear_svm <- caretStack(all.models, method='svmLinear',
                         trControl=trControl,tuneGrid=tune.grid)

# make SVM radial ensemble
trControl <- trainControl(method = "cv",  number=5)
tune.grid <- expand.grid(.sigma=expGrid(power.from=-14,
                                        power.to=10,power.by=1,base=2),
                         .C=expGrid(power.from=-14,power.to=10,
                                    power.by=2,base=2))
radial_svm <- caretStack(all.models, method='svmRadial',
                         trControl=trControl,tuneGrid=tune.grid)
@
%\end{enumerate}
We proceed to predict the bioactivities for the external (hold-out) set,
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
preds <- data.frame(sapply(all.models, predict, newdata=dataa$x.test))
preds$ENS_greedy <- predict(greedy, newdata=dataa$x.test)
preds$ENS_linear <- predict(linear, newdata=dataa$x.test)
preds$ENS_enet <- predict(enet_ens, newdata=x.test)
preds$ENS_SVMrad <- predict(radial_svm, newdata=x.test)c
preds$ENS_SVMlin <- predict(linear_svm, newdata=x.test)
@

and we calculate the metrics:
  
<<highlight=TRUE,tidy.opts=list(width.cutoff=50),tidy=TRUE,eval=FALSE>>=
# Calculate metrics (We could also have applied Validation instead.)
Q2s <- apply(preds,2, function(x) Qsquared(x,dataa$y.test))
R2s <- apply(preds,2, function(x) Rsquared(x,dataa$y.test))
R20s <- apply(preds,2, function(x) Rsquared0(x,dataa$y.test))
RMSEs <- apply(preds,2, function(x) RMSE(x,dataa$y.test))
@
%\section{Bibliography}
\newpage
\printbibliography

\end{document}