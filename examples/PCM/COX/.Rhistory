sd(a-b)
a-b
sd(a)
sd(b)
matrix(runif(25),5,5)
data = matrix(runif(25),5,5)
heatmap.2
library(ggplots2)
install.packages(ggplots2)
library("ggplots2")
install.packages("ggplots2)
c
ewofn
ç
))
quit
kwmd kwn
install.packages("ggplots2")
install.packages("gplots2")
heatmap2
heatmap.2
heatmap.
heatmap
heatmap(data)
data = matrix(runif(49),5,5)
data = matrix(runif(49),7,7)
heatmap(data)
heatmap(data,col=redgreen(256))
heatmap(data,col=red.green(256))
heatmap(data,col=red.green
)
heatmap(data,col=redgreen)
heatmap(data,col=red)
heatmap(data,col="redgreen")
heatmap(data,col="red.green")
heatmap(data,col="red")
install.packages("ggplot2")
heatmap.2(data)
heatmap2(data)
library("ggplot2")
heatmap2(data)
heatmap.2(data)
heatmap.2
heatmap(data)
heatmap2(data)
library("gplots")
install.packages("gplots")
library("gplots")
heatmap.2(data)
pdf("heatmap_feature_importance_GPCRs_seqs_130616_x.train.pdf",width=15,height=15)
library("ggplot2")
par(oma=c(3.5,3.5,3.5,3.5))
my.breaks <- c(seq(-0.25, -0.005, length.out=100),seq(-0.005, 0.005, length.out=57),seq(0.005,0.25, length.out=100))
heatmap.2(data_heatmap, Rowv=NA, labRow=seq(1,162,1),labCol=names,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=TRUE, keysize=1,trace="none",col=redblue(256),symm=T,symkey=T,symbreaks=
F,breaks=my.breaks)
dev.off()
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=FALSE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F)
data = matrix(runif(49),7,7)z
set.seed(1)
data = matrix(runif(49),7,7)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=FALSE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F)
set.seed(2)
data = matrix(runif(49),7,7)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=FALSE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=TRUE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=TRUE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F,count=FALSE)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=TRUE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F)
heatmap.2(data, Rowv=NA, labRow=NA,labCol=NA,Colv=NA,keep.dendro=FALSE, main="", xlab="",ylab="",key=TRUE,trace="none",col=redgreen(256),symm=T,symkey=T,symbreaks=
+               F,keysize=2)
list.files()
list.files()[1]
a = 3
class(a)
a = hola
class(a)
a
str(a)
a + 3
a = "hola"
class(a)
str(a)
type.of(a)
typeof(a)
install.packages(c("caret", "gbm", "rJava", "impute", "kernlab"))
install.packages("~/Desktop/Daniel/smPredict.zip", repos = NULL)
require("~/Desktop/Daniel/smPredict", repos = NULL)
require("~/Desktop/Daniel/smPredict")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
library("BiocInstaller", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("boot", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("diR", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
quit()
install.packages("packagename", repos="http://cran.wustl.edu")
install.packages("~/Desktop/camb/camb-master.zip", repos = NULL)
library(camb)
ImputeFeatures
proteome <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/proteome.csv",sep=",",header=T)
dim(proteome)
names(proteome)
# we use LFQ values
proteome2 <- proteome[,c(28:86)] # 87:ncol(proteome))]
dim(proteome2)
ABC <- read.table("/Users/icortes/Desktop/NCI60/ABC_transporters/nci60_RNA__ABC_Transporters_(RT_PCR)_log2.csv",sep=",",header=T)
dim(ABC)
names(ABC)[1:5]
ABC_data <- ABC[,5:ncol(ABC)]
dim(ABC_data)
miRNA <- read.table("/Users/icortes/Desktop/NCI60/Compounds/rdkit_tests/NCI60_RNA_miRNA_OSU_V3_chip_log2.csv",
sep="\t",header=T)
dim(miRNA)
names(miRNA)[1:5]
miRNA_data <- miRNA[,5:ncol(miRNA)]
dim(miRNA_data )
CNV<- read.table("/Users/icortes/Desktop/Drug_Sensitivity/NCI60_DNA__Combined_aCGH_gene_summary.txt",header=T,sep="\t")
CNV_names <- CNV$Probe.Name
dim(CNV)
names(CNV)
CNV<- CNV[,5:ncol(CNV)]
CNV[CNV=='null'] <- NA
CNV <- t(CNV)
CNV <- apply(CNV,2,as.numeric)
colnames(CNV) <- CNV_names
CNV[CNV<=-1] <- -1
CNV[CNV>=0.58] <- 1
CNV[(CNV > -1 & CNV < 0.58)] <- 0
CNVa <- CNV[, apply(CNV,2,function(x) {sum(is.na(x))}) == 0]
dim(CNVa)
CNVa <- CNVa[,which(apply(CNVa,2,sum)!=0)]
dim(CNVa)
# There are much more gains than losses:
sum(CNVa==-1)
#[1] 749
sum(CNVa==1)
#[1] 13138
CNVa <- CNVa[,(apply(CNVa,2,function(x){sum(x==0)})) < 58]
dim(CNVa)
colnames(CNVa)
write.table(colnames(CNVa),file="/Users/icortes/Desktop/Drug_Sensitivity/CNV_most_variant_CNV_names.csv",
sep=",",col.names=F,quote=F,row.names=F)
exome <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/nci60_DNA__Exome_Seq_none.txt",sep="\t",header=T)
dim(exome)
filter_typeII <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/Type2_variants",header=F,sep=",")
exome <- exome[as.vector(exome$dbSNP) %in% filter_typeII$V1, ]
polyphen <- exome$Polyphen
exome_genes <- as.vector(exome$Gene)
exome <- exome[which(polyphen > 0.85),19:ncol(exome)]
dim(exome)
PL <- read.table("/Users/icortes/Desktop/NCI60/Prot_lysate/nci60_Protein__Lysate_Array_log2.csv",sep=",",header=T)
dim(PL)
names(PL)[1:5]
PL_data <- PL[,5:ncol(PL)]
dim(PL_data)
PL_data<- as.data.frame(t(PL_data))
names(PL_data) <- PL$entrezgene_id
names(PL_data)
PL <- read.table("/Users/icortes/Desktop/NCI60/Prot_lysate/nci60_Protein__Lysate_Array_log2.csv",sep=",",header=T)
head(PL)
PL$symbol
PL$entrezgene_id
unique(PL$entrezgene_id)
dim(PL)
unique(PL$entrezgene_id)
unique(PL$symbol)
unique(PL$entrezgene_id)
unique(PL$symbol)
PL <- read.table("/Users/icortes/Desktop/NCI60/Prot_lysate/nci60_Protein__Lysate_Array_log2_condensed.csv",sep=",",header=T)
PL <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/nci60_Protein__Lysate_Array_log2_condensed.csv",sep=",",header=T)
PL <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/nci60_Protein__Lysate_Array_log2_condensed.csv",sep=",",header=T)
dim(PL)
names(PL)[1:5]
PL_data <- PL[,5:ncol(PL)]
dim(PL_data)
cell_names_NCI60_ipython <- as.vector(read.table("/Users/icortes/Desktop/NCI60/Compounds/rdkit_tests/BioRawCells.csv")$V1)
sum((names(PL_data) == cell_names_NCI60_ipython))
PL_data<- as.data.frame(t(PL_data))
names(PL_data) <- PL$entrezgene_id
names(PL_data)
names(PL_data) <- PL$symbol
names(PL_data)
write.table(names(PL_data),file="/Users/icortes/Desktop/Drug_Sensitivity/PL_gene_names.csv",quote=F,row.names=F,col.names=F)
proteome <- read.table("/Users/icortes/Desktop/Drug_Sensitivity/proteome.csv",sep=",",header=T)
dim(proteome)
names(proteome)
dim(proteome)
proteome2 <- proteome[,c(28:86)] # 87:ncol(proteome))]
names(proteome2)
rm(proteome)
rm(proteome2)
rm(CNV)
rm(exome)
rm(proteome)
library(camb)
d = data.frame(Y=seq(1,4),err=rep(1,4),X=c("A","B","C","D"))
# Example 1
ErrorBarplot(d$X,d$Y,d$err,fill=d$X,
main = "", ylab = "", xlab = "",
TextSize = 15, TitleSize = 15, XAxisSize = 15, YAxisSize = 15,
TitleAxesSize = 15, AngleLab = 35, barcol = "red", barSize = 1,
barWidth = 0.3, LegendName = "Legend", ColLegend = 1, RowLegend = NULL,
LegendPosition = "right", tmar = 1, bmar = 1, rmar = 1, lmar = 1,
stat = "identity")
# Example 2
ErrorBarplot(d$X,d$Y,d$err,fill=d$X,
main = "Example 2 ErrorBarplot", ylab = "Value", xlab = "Group",
TextSize = 15, TitleSize = 15, XAxisSize = 15, YAxisSize = 15,
TitleAxesSize = 15, AngleLab = 0, barcol = "green", barSize = 1,
barWidth = 0.6, LegendName = "Example Legend", ColLegend = 1, RowLegend = NULL,
LegendPosition = "right", tmar = 1, bmar = 1, rmar = 1, lmar = 1,
stat = "identity")
checkAA
AADescAll("A")
AADescAll
dim(AADescAll)
rownames(dim(AADescAll))
names(dim(AADescAll))
rownames(AADescAll)
AADescs("D")
AADescs("X")
AADescs(".")
checkModels_extractTypes
convert31
checkAA
greedOptAUC
checkAtAssignment
AADescs(c("A","A"))
AADescs
mergeData
checkAA
library(camb)
checkAtAssign
AADescs("A")
toupper("-")
library(camb)
AADescs("-")
AADescs("A")
library(camb)
AADescs("A")
AADescs("-")
AADescs("-","A")
AADescs(c("-","A"))
MaxPerf
slope
YScrambling
Rsquared
MAE
library(conformal)
ConformalClassificati
model <- read.rds("/Users/icortes/Desktop/rf.rds")
model <- readRDS("/Users/icortes/Desktop/rf.rds")
model
example <- ConformalClassification$new()
example$CalculateCVAlphas(model=model)
example$CalculatePValues(new.data=LogSDescsTest)
example$p.values$P.values
example$p.values$Significance_p.values
example$CalculateCVScored(model=model)
example$CalculateCVScores(model=model)
example$CalculatePValues(new.data=LogSDescsTest)
data(logS)
data(LogS)
data(logS)
example$CalculatePValues(new.data=LogSDescsTest)
model$finalModel
## Isidro Cortés Ciriano. 10/2014
## Conformal Prediction for caret classification models
#############################################
### Conformal Prediction for Classification
#############################################
ConformalClassification <- setRefClass(
"ConformalClassification",
fields = list(
ClassificationModel = "ANY",
confidence = "numeric",
data.new = "ANY",
NonconformityScoresMatrix ="ANY",
ClassPredictions = "ANY",
p.values = "ANY"
),
methods = list(
initialize = function(confi = 0.8)
{
"This method is called when you create an instance of the class."
if (confi > 1 || confi < 0)
stop("Confidence must be between 0 and 1")
confidence <<- confi
cat("Conformal Prediction Class for Classification Instantiated")
cat("\n")
},
CalculateCVScores = function(model=NULL)
{
if(is.null(model))
stop("To calculate the alphas, a point prediction model and an error model
need to be suppplied")
if(model$modelType != "Classification" )
stop("The model type needs to be 'Classification'")
ClassificationModel <<- model
print("Calculating the vector of nonconformity measures for the CV predictions (label wise Mondrian ICP)..")
cat('\n')
MondrianICP <- model$finalModel$votes
MondrianICP <- apply(MondrianICP, 2, sort, decreasing=FALSE)
NonconformityScoresMatrix <<- MondrianICP
},
CalculatePValues = function(new.data=NULL)
{
if (is.null(new.data)){
stop("\nArgument 'data.new' cannot be empty.\nNew datapoints are required as input\n")
}
else{
data.new <<- new.data
}
require("caret") || stop("Pacakge 'caret' is required to make new predictions")
print("Classifying the input data..")
cat('\n')
pred <- predict(ClassificationModel, newdata = new.data,predict.all=TRUE) # individual or aggregate
ClassPredictions <<- pred
ntrees <- model$finalModel$ntree
votes <- apply(pred$individual,1,function(x){table(x)})
out<-c()
for (i in colnames(NonconformityScoresMatrix)){
out<-cbind(out,sapply(votes,function(x) x[i]))
}
out[is.na(out)] <- 0
out <- out/ntrees
colnames(out) <- colnames(NonconformityScoresMatrix)
pval <- t(apply(out,1,function(x){ apply(do.call(rbind, lapply(as.data.frame(t(NonconformityScoresMatrix)), "<", x)),2,sum)    }))
pval <- pval / nrow(NonconformityScoresMatrix)
# this also works but is slower
# library(plyr)
# now <- t(apply(out,1,function(x){ apply(aaply(NonconformityScoresMatrix, 1, "<", x),2,sum)    }))
# http://stackoverflow.com/questions/20596433/how-to-divide-each-row-of-a-matrix-by-elements-of-a-vector-in-r
pval_signif <- (pval > (1-confidence))*1
p.values <<- list(P.values = pval,Significance_p.values = pval_signif)
}
)
)
example$CalculateCVScores(model=model)
example$CalculatePValues(new.data=LogSDescsTest)
pred <- predict(model, newdata = LogSDescsTest)
pred <- predict(model$finalModel, newdata = LogSDescsTest)
pred <- predict(model, newdata = LogSDescsTest)
?predict.randomForest
library(randomForest)
pred <- predict(model, newdata = LogSDescsTest)
library(randomForest)
example <- ConformalClassification$new()
example$CalculateCVScores(model=model)
example$CalculatePValues(new.data=LogSDescsTest)
example$p.values$P.values
example$p.values$Significance_p.values
## Isidro Cortés Ciriano. 10/2014
## Conformal Prediction for caret classification models
#############################################
### Conformal Prediction for Classification
#############################################
ConformalClassification <- setRefClass(
"ConformalClassification",
fields = list(
ClassificationModel = "ANY",
confidence = "numeric",
data.new = "ANY",
NonconformityScoresMatrix ="ANY",
ClassPredictions = "ANY",
p.values = "ANY"
),
methods = list(
initialize = function(confi = 0.8)
{
"This method is called when you create an instance of the class."
if (confi > 1 || confi < 0)
stop("Confidence must be between 0 and 1")
confidence <<- confi
cat("Conformal Prediction Class for Classification Instantiated")
cat("\n")
},
CalculateCVScores = function(model=NULL)
{
if(is.null(model))
stop("To calculate the alphas, a point prediction model and an error model
need to be suppplied")
if(model$modelType != "Classification" )
stop("The model type needs to be 'Classification'")
ClassificationModel <<- model
print("Calculating the vector of nonconformity measures for the CV predictions (label wise Mondrian ICP)..")
cat('\n')
MondrianICP <- model$finalModel$votes
MondrianICP <- apply(MondrianICP, 2, sort, decreasing=FALSE)
NonconformityScoresMatrix <<- MondrianICP
},
CalculatePValues = function(new.data=NULL)
{
if (is.null(new.data)){
stop("\nArgument 'data.new' cannot be empty.\nNew datapoints are required as input\n")
}
else{
data.new <<- new.data
}
require("caret") || stop("Pacakge 'caret' is required to make new predictions")
print("Classifying the input data..")
cat('\n')
pred <- predict(ClassificationModel$finalModel, newdata = new.data,predict.all=TRUE) # individual or aggregate
ClassPredictions <<- pred
ntrees <- model$finalModel$ntree
votes <- apply(pred$individual,1,function(x){table(x)})
out<-c()
for (i in colnames(NonconformityScoresMatrix)){
out<-cbind(out,sapply(votes,function(x) x[i]))
}
out[is.na(out)] <- 0
out <- out/ntrees
colnames(out) <- colnames(NonconformityScoresMatrix)
pval <- t(apply(out,1,function(x){ apply(do.call(rbind, lapply(as.data.frame(t(NonconformityScoresMatrix)), "<", x)),2,sum)    }))
pval <- pval / nrow(NonconformityScoresMatrix)
# this also works but is slower
# library(plyr)
# now <- t(apply(out,1,function(x){ apply(aaply(NonconformityScoresMatrix, 1, "<", x),2,sum)    }))
# http://stackoverflow.com/questions/20596433/how-to-divide-each-row-of-a-matrix-by-elements-of-a-vector-in-r
pval_signif <- (pval > (1-confidence))*1
p.values <<- list(P.values = pval,Significance_p.values = pval_signif)
}
)
)
example <- ConformalClassification$new()
example$CalculateCVScores(model=model)
example$CalculatePValues(new.data=LogSDescsTest)
example$p.values$P.values
example$p.values$Significance_p.values
head(example$p.values$Significance_p.values)
head(example$p.values$P.values)
x.test[1:3,1:3]
LogSDescsTest[1:3,1:3]
Split
library(camb)
SplitSet
install.packages("ggvis")
library(ggvis)
install.packages("dplyr")
version()
install.packages("dplyr")
install.packages("shiny")
install.packages("dplyr")
install.packages("ggvis")
library(ggvis)
mtcars %>%
ggvis(~wt, ~mpg) %>%
layer_smooths(span = input_slider(0.5, 1, value = 1)) %>%
layer_points(size := input_slider(100, 1000, value = 100))
ggvis(~wt, ~mpg)
mtcars
names(mtcars)
??ggvis
?layer_densities
install.packages("ensurer")
install.packages("ensurer")
devtools::install_github("smbache/ensurer")
library(ensurer)
library(magrittr)
m = matrix(20)
m
NCOL(m)
ensure_square <- ensures_that(NCOL(.) == NROW(.))
ensure_square(m)
ensure_square
ensure_square(m)
d = ensure_square(m)
d
library(camb)
AADescs("fg")
AADescs("-")
library(camb)
library(camb)
StandardiseMolecules(structures.file = "c19_all_gpcr_cmp_structures.sdf",standardised.file = "standardised.sdf",
removed.file = "removed.sdf",remove.inorganic = "T")
plot_molecules <- PlotMolecules(sdf.file = "standardised.sdf",IDs=c(1,2,3,4),pdf.file=NULL,useNameAsTitle=TRUE,PDFMain=NULL)
When using integrated development environments (IDE) such as RStudio,
the environment variables might not be defined within the R session.
library(camb)
StandardiseMolecules
StandardiseMolecules(structures.file="smiles_COX.smi",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
properties.file = "standardisation_info.csv",
remove.inorganic=TRUE,
fluorine.limit=-1,
chlorine.limit=-1,
bromine.limit=-1,
iodine.limit=-1,
min.mass.limit=-1, #suggested value 20
max.mass.limit=-1) #suggested value  900
setwd('/Users/icortes/Desktop/camb_final/camb/examples/PCM/COX')
StandardiseMolecules(structures.file="smiles_COX.smi",
standardised.file="standardised.sdf",
removed.file="removed.sdf",
properties.file = "standardisation_info.csv",
remove.inorganic=TRUE,
fluorine.limit=-1,
chlorine.limit=-1,
bromine.limit=-1,
iodine.limit=-1,
min.mass.limit=-1, #suggested value 20
max.mass.limit=-1) #suggested value  900
